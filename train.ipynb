{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#The following instructions can be used to train a Transformer model on the [IWSLT'14 German to English dataset](http://workshop2014.iwslt.org/downloads/proceeding.pdf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://127.0.0.1:8888/'. Verify the server is running and reachable. (Failed to connect to the remote Jupyter Server 'http://127.0.0.1:8888/'. Verify the server is running and reachable. (request to http://127.0.0.1:8888/api/kernels?1711129868677 failed, reason: connect ECONNREFUSED 127.0.0.1:8888).)."
     ]
    }
   ],
   "source": [
    "\n",
    "%%bash \n",
    "\n",
    "cd /mnt/c/translator\n",
    "cd cli/\n",
    "bash prepare-wmt14en2de.sh\n",
    "cd ../.\n",
    "\n",
    "TEXT=cli/wmt17_en_de\n",
    "fairseq-preprocess \n",
    "    --source-lang en --target-lang de \\\n",
    "    --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test \\\n",
    "    --destdir data-bin/wmt17_en_de --thresholdtgt 0 --thresholdsrc 0 \\\n",
    "    --workers 20\n",
    "    \n",
    "mkdir -p checkpoints/fconv_wmt_en_de\n",
    "# fairseq-train \\\n",
    "#     data-bin/wmt17_en_de \\\n",
    "#     --arch fconv_wmt_en_de \\\n",
    "#     --dropout 0.2 \\\n",
    "#     --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "#     --optimizer nag --clip-norm 0.1 \\\n",
    "#     --lr 0.5 --lr-scheduler fixed --force-anneal 50 \\\n",
    "#     --max-tokens 4000 \\\n",
    "#     --save-dir checkpoints/fconv_wmt_en_de\n",
    "# alias python=python3\n",
    "\n",
    "\n",
    "    \n",
    "# cd examples/translation/\n",
    "# bash wmt14en-de.sh\n",
    "# cd ../..\n",
    "\n",
    "# # Preprocess/binarize the data\n",
    "# TEXT=examples/translation/wmt14en2de.tokenized.de-en\n",
    "# fairseq-preprocess --source-lang de --target-lang en \\\n",
    "#     --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test \\\n",
    "#     --destdir data-bin/wmt14en2de.tokenized.de-en \\\n",
    "#     --workers 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/fairseq-train\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/fairseq_cli/train.py\", line 541, in cli_main\n",
      "    parser = options.get_training_parser()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/fairseq/options.py\", line 38, in get_training_parser\n",
      "    parser = get_parser(\"Trainer\", default_task)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/fairseq/options.py\", line 234, in get_parser\n",
      "    utils.import_user_module(usr_args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/fairseq/utils.py\", line 491, in import_user_module\n",
      "    importlib.import_module(module_name)\n",
      "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 992, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/mnt/c/translator/models/transformer_legacy.py\", line 11, in <module>\n",
      "    from models.transformer_config import (\n",
      "ModuleNotFoundError: No module named 'models'\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'CUDA_VISIBLE_DEVICES=0 fairseq-train \\\\\\n    data-bin/wmt17_en_de \\\\\\n    --arch meta-transformer_wmt_de_en --share-decoder-input-output-embed \\\\\\n    --user-dir models/transformer_legacy.py\\\\\\n    --optimizer adam --adam-betas \\'(0.9, 0.98)\\' --clip-norm 0.0 \\\\\\n    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\\\\n    --dropout 0.3 --weight-decay 0.0001 \\\\\\n    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\\\\n    --max-tokens 500 \\\\\\n    --eval-bleu \\\\\\n    --eval-bleu-args \\'{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}\\' \\\\\\n    --eval-bleu-detok moses \\\\\\n    --eval-bleu-remove-bpe \\\\\\n    --eval-bleu-print-samples \\\\\\n    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCUDA_VISIBLE_DEVICES=0 fairseq-train \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    data-bin/wmt17_en_de \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --arch meta-transformer_wmt_de_en --share-decoder-input-output-embed \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --user-dir models/transformer_legacy.py\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --optimizer adam --adam-betas \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m(0.9, 0.98)\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m --clip-norm 0.0 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --dropout 0.3 --weight-decay 0.0001 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --max-tokens 500 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --eval-bleu \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --eval-bleu-args \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbeam\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m: 5, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_len_a\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m: 1.2, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_len_b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m: 10}\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --eval-bleu-detok moses \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --eval-bleu-remove-bpe \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --eval-bleu-print-samples \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:2541\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2540\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2541\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2543\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2544\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2545\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/script.py:155\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/script.py:315\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'CUDA_VISIBLE_DEVICES=0 fairseq-train \\\\\\n    data-bin/wmt17_en_de \\\\\\n    --arch meta-transformer_wmt_de_en --share-decoder-input-output-embed \\\\\\n    --user-dir models/transformer_legacy.py\\\\\\n    --optimizer adam --adam-betas \\'(0.9, 0.98)\\' --clip-norm 0.0 \\\\\\n    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\\\\n    --dropout 0.3 --weight-decay 0.0001 \\\\\\n    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\\\\n    --max-tokens 500 \\\\\\n    --eval-bleu \\\\\\n    --eval-bleu-args \\'{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}\\' \\\\\\n    --eval-bleu-detok moses \\\\\\n    --eval-bleu-remove-bpe \\\\\\n    --eval-bleu-print-samples \\\\\\n    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "# %%bash \n",
    "# CUDA_VISIBLE_DEVICES=0 fairseq-train \\\n",
    "#     data-bin/wmt17_en_de \\\n",
    "#     --arch meta_transformer_wmt_de_en --share-decoder-input-output-embed \\\n",
    "#     --user-dir transformer\\\n",
    "#     --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "#     --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "#     --dropout 0.3 --weight-decay 0.0001 \\\n",
    "#     --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "#     --max-tokens 500 \\\n",
    "#     --eval-bleu \\\n",
    "#     --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
    "#     --eval-bleu-detok moses \\\n",
    "#     --eval-bleu-remove-bpe \\\n",
    "#     --eval-bleu-print-samples \\\n",
    "#     --best-checkpoint-metric bleu --maximize-best-checkpoint-metric\n",
    "    fairseq-train ^\n",
    "    data-bin/wmt17_en_de ^\n",
    "    --arch meta_transformer_wmt_de_en --share-decoder-input-output-embed ^\n",
    "    --user-dir transformer^\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 ^\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 ^\n",
    "    --dropout 0.3 --weight-decay 0.0001 ^\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 ^\n",
    "    --max-tokens 500 ^\n",
    "    --eval-bleu ^\n",
    "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' ^\n",
    "    --eval-bleu-detok moses ^\n",
    "    --eval-bleu-remove-bpe ^\n",
    "    --eval-bleu-print-samples ^\n",
    "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "fairseq-generate data-bin/iwslt14.tokenized.de-en \\\n",
    "    --path checkpoints/checkpoint_best.pt \\\n",
    "    --batch-size 128 --beam 5 --remove-bpe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
